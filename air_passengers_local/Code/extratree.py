#!/usr/bin/env python3# -*- coding: utf-8 -*-"""Created on Sun Apr 26 15:27:47 2020@author: dorian"""import osimport importlibimport numpy as npimport pandas as pdimport matplotlib.pyplot as pltfrom sklearn.preprocessing import OrdinalEncoder, OneHotEncoderfrom sklearn.compose import make_column_transformerfrom sklearn.ensemble import ExtraTreesRegressorfrom sklearn.pipeline import make_pipelinefrom sklearn.model_selection import cross_val_scoreimport problemfrom sklearn.model_selection import RandomizedSearchCVfrom sklearn.impute import SimpleImputerfrom sklearn.preprocessing import FunctionTransformerfrom sklearn.inspection import permutation_importancefrom sklearn.model_selection import train_test_splitimport shapdef _merge_external_data(X):    filepath = os.path.join(        os.path.dirname(__file__), 'external_data.csv'    )    # Make sure that DateOfDeparture is of dtype datetime    X = X.copy()  # modify a copy of X    X.loc[:, "DateOfDeparture"] = pd.to_datetime(X['DateOfDeparture'])    # Parse date to also be of dtype datetime    data_weather = pd.read_csv(filepath, parse_dates=["DateOfDeparture"])    X_weather = data_weather[['DateOfDeparture', 'Arrival',                              'Max TemperatureC', 'Mean VisibilityKm', 'holidays']]    X_merged = pd.merge(        X, X_weather, how='left', on=['DateOfDeparture', 'Arrival'], sort=False    )    return X_mergeddef _encode_dates(X):    # Make sure that DateOfDeparture is of dtype datetime    X = X.copy()  # modify a copy of X    X.loc[:, "DateOfDeparture"] = pd.to_datetime(X['DateOfDeparture'])    # Encode the date information from the DateOfDeparture columns    X.loc[:, 'year'] = X['DateOfDeparture'].dt.year    X.loc[:, 'month'] = X['DateOfDeparture'].dt.month    X.loc[:, 'day'] = X['DateOfDeparture'].dt.day    X.loc[:, 'weekday'] = X['DateOfDeparture'].dt.weekday    X.loc[:, 'week'] = X['DateOfDeparture'].dt.week    X.loc[:, 'n_days'] = X['DateOfDeparture'].apply(        lambda date: (date - pd.to_datetime("1970-01-01")).days    )    # Finally we can drop the original columns from the dataframe    return X.drop(columns=["DateOfDeparture"])#Loading  training dataX, y = problem.get_train_data()#########################################################################################################################                                            #Extra Trees with OneHotEncoder######################################################################################################################################################################Preprocessing training data#####################################data_merger = FunctionTransformer(_merge_external_data)date_encoder = FunctionTransformer(_encode_dates)date_cols = ["DateOfDeparture"]categorical_encoder = make_pipeline(        SimpleImputer(strategy="constant", fill_value="missing"),        OneHotEncoder(handle_unknown="ignore",sparse = True)    )categorical_cols = [    "Arrival", "Departure", "day", "weekday", "holidays", "week", "n_days"    ]preprocessor = make_column_transformer(    (categorical_encoder, categorical_cols),)#############################################Find best parameters#############################################"""parameters = {'extratreesregressor__n_estimators': [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)],               'extratreesregressor__max_features': ['auto', 'sqrt'],               'extratreesregressor__max_depth': [int(x) for x in np.linspace(10, 110, num = 11)],               'extratreesregressor__min_samples_split': [int(x) for x in np.linspace(2, 20, num = 8)],               'extratreesregressor__min_samples_leaf': [int(x) for x in np.linspace(1, 20, num = 10)],               'extratreesregressor__bootstrap': [True, False]}pipeline_cv = make_pipeline(data_merger, date_encoder,preprocessor, ExtraTreesRegressor())cv_et = RandomizedSearchCV(pipeline_cv, parameters, cv=5, n_iter = 100)cv_et.fit(X, y)best_parameters = cv_et.best_params_"""#############################################Create pipeline with best parameters###############################Best parametersn_estimators = 50max_features = 'auto'max_depth = Nonemin_samples_leaf = 1random_state = 0regressor = ExtraTreesRegressor(n_estimators=n_estimators,                             max_features=max_features,                             max_depth=max_depth,                             min_samples_leaf=min_samples_leaf,                             random_state=random_state)pipeline = make_pipeline(data_merger,date_encoder,preprocessor, regressor)scores = cross_val_score(    pipeline, X, y, cv=5, scoring='neg_mean_squared_error')rmse_scores = np.sqrt(-scores)print(    f"RMSE: {np.mean(rmse_scores):.4f} +/- {np.std(rmse_scores):.4f}")#RMSE: 0.5126 +/- 0.0230